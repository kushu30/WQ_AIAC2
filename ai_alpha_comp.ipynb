{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9442c62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ace_lib as ace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df00909",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ace.start_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451a2f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ace.check_session_timeout(s) < 3000:\n",
    "    s = ace.check_session_and_relogin(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e7b28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_operators_reference(brain_session) -> str:\n",
    "    operators_df = ace.get_operators(brain_session)\n",
    "    operators_df = operators_df[operators_df['scope']=='REGULAR']\n",
    "    operators_df = operators_df[['name', 'category', 'definition', 'description']]\n",
    "    operators_df['description'] = operators_df['description'].apply(lambda x : x.replace('\\r\\n', ' ').replace('\\n', ' ').replace('\\r', ' ') if isinstance(x, str) else x)\n",
    "    operators_table = operators_df.to_markdown(index=False, tablefmt='github')\n",
    "    operators_table_description = \"\"\"## WorldQuant BRAIN Operators Reference\n",
    "\n",
    "### Table Structure\n",
    "- `name`: The name of the operator or function (e.g., `abs`, `add`, `log`).\n",
    "- `category`: The classification of the operator based on its functionality (e.g., Arithmetic, Logical, Time Series, etc.).\n",
    "- `definition`: A concise syntax or formula that describes how the operator is used.\n",
    "- `description`: A brief explanation of what the operator does, including its purpose and behavior.\n",
    "\n",
    "### Categories\n",
    "1. Arithmetic: Operators for mathematical operations like addition, subtraction, multiplication, division, logarithms, and exponentials.\n",
    "\n",
    "2. Logical: Operators for logical comparisons and conditions, such as AND, OR, NOT, and equality checks..\n",
    "\n",
    "3. Time Series: Operators for analyzing and manipulating time-series data, such as calculating moving averages, delays, or correlations over a specified number of days..\n",
    "\n",
    "4. Cross Sectional: Operators for working with data across multiple instruments or entities at a single point in time, such as ranking, scaling, and normalization.\n",
    "\n",
    "5. Vector: Operators for vector-based calculations, such as finding the sum, mean, or standard deviation of elements in a vector.\n",
    "\n",
    "6. Transformational: Operators for transforming data, such as filtering, clamping, or tailing values based on conditions.\n",
    "\n",
    "7. Group: Operators for group-based calculations, such as neutralizing, ranking, or scaling values within groups (e.g., sectors or industries).\n",
    "\n",
    "8. Special: Operators for specific use cases, such as converting between units or calculating profit and loss.\n",
    "\n",
    "\"\"\"\n",
    "    return operators_table_description + \"\\n\" + operators_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b02ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example output\n",
    "print(get_operators_reference(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f575631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_reference(brain_session, dataset_id, region='USA', universe='TOP3000') -> str:\n",
    "    datasets_df = ace.get_datasets(brain_session, region=region, universe=universe)\n",
    "    dataset = datasets_df[datasets_df['id'] == dataset_id].iloc[0]\n",
    "    dataset_details = f\"\"\"\n",
    "## Dataset Details\n",
    "\n",
    "ID: {dataset['id']}\n",
    "Name: {dataset['name']}\n",
    "Category Name: {dataset['category_name']}\n",
    "Subcategory Name: {dataset['subcategory_name']}\n",
    "Description: {dataset['description']}\n",
    "\n",
    "Below is the reference table to available datafields:\n",
    "\"\"\"\n",
    "    datafields_df = ace.get_datafields(brain_session, dataset_id=dataset_id, region=region, universe=universe)\n",
    "    datafields_df = datafields_df[['id', 'description', 'type', 'dateCoverage', 'coverage', 'alphaCount']] # feel free to add or remove columns\n",
    "    datafields_df['description'] = datafields_df['description'].apply(lambda x : x.replace('\\r\\n', ' ').replace('\\n', ' ').replace('\\r', ' ') if isinstance(x, str) else x)\n",
    "    datafields_table = datafields_df.to_markdown(index=False, tablefmt='github')\n",
    "\n",
    "    return dataset_details + \"\\n\" + datafields_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d82992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example output\n",
    "print(get_dataset_reference(s, \"model110\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b9e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class AlphaExpression(BaseModel):\n",
    "    \"\"\"Structured output for a single alpha expression\"\"\"\n",
    "    alpha_expression: str = Field(description=\"Alpha expression in WorldQuant Brain syntax\")\n",
    "    economic_rationale: str = Field(description=\"Economic reasoning behind the alpha expression\")\n",
    "    data_fields_used: List[str] = Field(description=\"List of data fields/features used in the expression\")\n",
    "    operators_used: List[str] = Field(description=\"List of operators used in the expression\")\n",
    "\n",
    "\n",
    "class AlphaExpressions(BaseModel):\n",
    "    \"\"\"Collection of alpha expressions\"\"\"\n",
    "    alphas: List[AlphaExpression] = Field(description=\"List of generated alpha expressions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f6ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "OPENAI_API_KEY = \"YOUR_OPENAI_API_KEY\" # or os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_BASE_URL = \"OPENAI_BASE_URL\" # or os.getenv(\"OPENAI_BASE_URL\") \n",
    "\n",
    "def call_llm(messages: List[Dict], output_structure: BaseModel):\n",
    "    # Initialize OpenAI client\n",
    "    client = OpenAI(base_url = OPENAI_BASE_URL, api_key=OPENAI_API_KEY)\n",
    "    \n",
    "    # Call OpenAI API with structured output\n",
    "    completion = client.chat.completions.parse(\n",
    "        model=\"gpt-5.1\",  # Model that supports structured outputs\n",
    "        messages=messages,\n",
    "        response_format=output_structure,\n",
    "        temperature=0.3,  # Higher temperature for more diverse expressions\n",
    "        max_tokens=4000\n",
    "    )\n",
    "    \n",
    "    # Extract structured output\n",
    "    llm_structured_output = completion.choices[0].message.parsed\n",
    "    \n",
    "    return llm_structured_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5979f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_alpha_expressions(hypothesis: str, operators_reference: str, dataset_reference: str, num_alphas: int = 10) -> AlphaExpressions:\n",
    "\n",
    "    \n",
    "    # Construct prompts for alpha generation\n",
    "\n",
    "    system_prompt = \"You are an expert quantitative researcher with deep knowledge of WorldQuant Brain alpha expressions, financial markets, and quantitative trading strategies.\"\n",
    "    \n",
    "    user_prompt = f\"\"\"You are an expert quantitative researcher specializing in creating alpha expressions for WorldQuant Brain platform.\n",
    "\n",
    "Given the following investment hypothesis or idea:\n",
    "\"{hypothesis}\"\n",
    "\n",
    "Generate {num_alphas} diverse alpha expressions that capture different aspects of this hypothesis.\n",
    "\n",
    "Here are the dataset details and available data fields:\n",
    "\n",
    "{dataset_reference}\n",
    "\n",
    "Here is the operators reference:\n",
    "\n",
    "{operators_reference}\n",
    "\n",
    "IMPORTANT REQUIREMENTS:\n",
    "\n",
    "1. **WorldQuant Brain Syntax**: Use proper WorldQuant Brain syntax and strictly use provided operators references.\n",
    "\n",
    "2. **Expression Diversity**: Each alpha should:\n",
    "   - Use different combinations of operators and data fields\n",
    "   - Capture different aspects of the hypothesis (momentum, value, quality, volatility, etc.)\n",
    "   - Vary in complexity (some simple, some more sophisticated)\n",
    "   - Consider different time horizons (short-term vs long-term)\n",
    "\n",
    "3. **Economic Rationale**: Provide clear, concise economic reasoning that:\n",
    "   - Explains WHY the alpha should work\n",
    "   - Links back to the original hypothesis\n",
    "   - Describes the market inefficiency or behavioral bias being exploited\n",
    "   - Is specific to the alpha expression (not generic)\n",
    "\n",
    "4. **Data Fields**: List ALL data fields actually used in the expression\n",
    "   - Be specific (e.g., \"close\", \"volume\", \"market_cap\")\n",
    "   - Include derived fields if relevant\n",
    "\n",
    "5. **Operators**: List ALL operators used in the expression\n",
    "   - Include both time-series and cross-sectional operators\n",
    "   - Be comprehensive and accurate\n",
    "\n",
    "EXAMPLE FORMAT (for reference):\n",
    "- Alpha Expression: rank(ts_delta(close, 5) / ts_std_dev(close, 20))\n",
    "- Economic Rationale: Captures short-term momentum normalized by recent volatility, identifying stocks with strong recent price moves relative to their volatility\n",
    "- Data Fields: [\"close\"]\n",
    "- Operators: [\"rank\", \"ts_delta\", \"ts_std_dev\"]\n",
    "\n",
    "Now generate {num_alphas} high-quality alpha expressions based on the hypothesis provided.\"\"\"\n",
    "\n",
    "    # Call LLM\n",
    "    messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt          },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    # Extract structured output\n",
    "    alpha_expressions = call_llm(messages, AlphaExpressions)\n",
    "    \n",
    "    return alpha_expressions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ac9e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_alpha_expressions(alpha_expressions: AlphaExpressions):\n",
    "    \"\"\"\n",
    "    Pretty print the generated alpha expressions.\n",
    "    \n",
    "    Args:\n",
    "        alpha_expressions: AlphaExpressions object to print\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Generated {len(alpha_expressions.alphas)} Alpha Expressions\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    for i, alpha in enumerate(alpha_expressions.alphas, 1):\n",
    "        print(f\"Alpha #{i}\")\n",
    "        print(f\"{'-'*80}\")\n",
    "        print(f\"Expression: {alpha.alpha_expression}\")\n",
    "        print(f\"\\nEconomic Rationale:\\n{alpha.economic_rationale}\")\n",
    "        print(f\"\\nData Fields Used: {', '.join(alpha.data_fields_used)}\")\n",
    "        print(f\"Operators Used: {', '.join(alpha.operators_used)}\")\n",
    "        print(f\"\\n{'='*80}\\n\")\n",
    "\n",
    "\n",
    "def export_to_dict(alpha_expressions: AlphaExpressions) -> List[dict]:\n",
    "    return [alpha.model_dump() for alpha in alpha_expressions.alphas]\n",
    "\n",
    "def export_to_json(alpha_dicts: List[Dict]):\n",
    "    import json\n",
    "    with open('alphas.json', 'w') as json_file:\n",
    "        json.dump(alpha_dicts, json_file, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12909ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example hypothesis\n",
    "hypothesis = \"Stocks with increasing revenue growth and low volatility outperform the market\"\n",
    "operators_reference = get_operators_reference(s)\n",
    "dataset_reference = get_dataset_reference(s, dataset_id=\"model110\")\n",
    "\n",
    "print(f\"Generating alpha expressions for hypothesis:\\n'{hypothesis}'\\n\")\n",
    "\n",
    "# Generate alpha expressions\n",
    "result = generate_alpha_expressions(hypothesis, operators_reference, dataset_reference, num_alphas=10)\n",
    "\n",
    "# Print results\n",
    "print_alpha_expressions(result)\n",
    "\n",
    "# Export to dict for further use\n",
    "alpha_dicts = export_to_dict(result)\n",
    "print(f\"Exported {len(alpha_dicts)} alpha expressions to dictionary format\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3e68c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate alphas\n",
    "\n",
    "alpha_list = []\n",
    "for alpha_dict in alpha_dicts:\n",
    "    alpha = ace.generate_alpha(\n",
    "            regular=alpha_dict['alpha_expression'],\n",
    "            alpha_type=\"REGULAR\",\n",
    "            region=\"USA\",\n",
    "            universe=\"TOP1000\",\n",
    "            delay=1,\n",
    "            neutralization=\"SECTOR\",\n",
    "            decay=4,\n",
    "            truncation=0.02,\n",
    "            pasteurization=\"ON\",\n",
    "            test_period=\"P2Y\",\n",
    "            unit_handling=\"VERIFY\",\n",
    "            nan_handling=\"ON\",\n",
    "            max_trade=\"OFF\",\n",
    "            visualization=True,\n",
    "        )\n",
    "    alpha_dict['alpha_settings'] = alpha\n",
    "    alpha_list.append(alpha)\n",
    "\n",
    "\n",
    "export_to_json(alpha_dicts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Unified Wrappers)",
   "language": "python",
   "name": "unified_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
